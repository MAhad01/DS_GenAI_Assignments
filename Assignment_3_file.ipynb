{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33baaac4-68c9-4e3c-a9b9-fb798b3a8661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Write a code to read the contents of a file in Python&\n",
    "\n",
    "\n",
    "file_path = 'sample.txt'\n",
    "    \n",
    "with open(file_path, 'r') as file:\n",
    "    file_content = file.read()\n",
    "    print(\"File content:\")\n",
    "    print(file_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "937b76d2-1053-4b9a-8c0a-6e66ac2559e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content written to 'output.txt' successfully.\n"
     ]
    }
   ],
   "source": [
    "# 2 Write a code to write to a file in Python&\n",
    "\n",
    "\n",
    "file_path = 'output.txt'\n",
    "\n",
    "try:\n",
    "    \n",
    "    with open(file_path, 'w') as file:\n",
    "        \n",
    "        file.write(\"Hello, world!\\n\")\n",
    "        file.write(\"This is a sample file.\\n\")\n",
    "        file.write(\"Feel free to add more lines!\")\n",
    "\n",
    "    print(f\"Content written to '{file_path}' successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97b096bf-ef93-4c8d-8f9d-870b66462eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content appended to 'my_notes.txt' successfully.\n"
     ]
    }
   ],
   "source": [
    "# 3 Write a code to append to a file in Python&\n",
    "\n",
    "\n",
    "file_path = 'my_notes.txt'\n",
    "\n",
    "try:\n",
    "    \n",
    "    with open(file_path, 'a') as file:\n",
    "        \n",
    "        file.write(\"This is a new line appended to the file.\\n\")\n",
    "\n",
    "    print(f\"Content appended to '{file_path}' successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b35a1ecc-2e73-442e-9c37-05d7106f8725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary file 'my_binary_file.dat' not found.\n"
     ]
    }
   ],
   "source": [
    "# 4 & Write a code to read a binary file in Python&\n",
    "\n",
    "\n",
    "binary_file_path = 'my_binary_file.dat'\n",
    "\n",
    "try:\n",
    "    \n",
    "    with open(binary_file_path, 'rb') as binary_file:\n",
    "        \n",
    "        content = binary_file.read(10)\n",
    "        print(f\"First 10 bytes of '{binary_file_path}': {content}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Binary file '{binary_file_path}' not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5532d940-f2f5-40c1-8f1e-3f4bc8dd9b96",
   "metadata": {},
   "source": [
    "# 5 What happens if we don't use `with` keyword with `open` in pytho\n",
    "\n",
    "If you don't use the with keyword, you need to manually close the file using the close method. Failing to do so can lead to several issues:\n",
    "\n",
    "Resource Leaks: Open file descriptors consume system resources. If many files are opened without being closed, it can exhaust the file descriptor limit of the operating system, leading to errors.\n",
    "\n",
    "Data Integrity: Data might not be written to the file properly. This can happen because the data is buffered and might not be flushed to the file until it is closed.\n",
    "\n",
    "Memory Leaks: Not closing files can result in memory not being released, leading to memory leaks.\n",
    "\n",
    "File Locks: If a file remains open, it might stay locked, preventing other programs or processes from accessing it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cd8e16-e2f8-4aeb-b7e5-57a4b4a4ae75",
   "metadata": {},
   "source": [
    "# 6  Explain the concept of buffering in file handling and how it helps in improving read and write operations&\n",
    "\n",
    "Buffering in file handling is a technique used to improve the efficiency of read and write operations by reducing the number of system calls. Instead of reading or writing data directly to or from a file each time, data is first stored in a temporary storage area called a buffer. When the buffer is filled or when the file is closed, the data is written to or read from the file in larger chunks. This minimizes the overhead associated with multiple I/O operations.\n",
    "\n",
    "How Buffering Works\n",
    "Read Buffering:\n",
    "\n",
    "When a file is read, a chunk of data is first loaded into the buffer.\n",
    "Subsequent read operations fetch data from this buffer until it is exhausted.\n",
    "When the buffer is empty, the next chunk of data is loaded from the file into the buffer.\n",
    "Write Buffering:\n",
    "\n",
    "When data is written to a file, it is first placed in the buffer.\n",
    "Once the buffer is full or the file is closed, the data in the buffer is written to the file in one go.\n",
    "This reduces the number of write operations to the file, improving performance.\n",
    "Types of Buffering\n",
    "Full Buffering: Data is stored in the buffer until it is full, at which point it is written to the file in one operation. This is the default mode for most files.\n",
    "Line Buffering: Data is buffered until a newline character is encountered. This is typically used for text files where you want to process data line by line.\n",
    "Unbuffered: No buffering is used, meaning that each read or write operation directly interacts with the file. This mode is less efficient but necessary in some real-time applications.\n",
    "Benefits of Buffering\n",
    "Improved Performance: By reducing the number of system calls, buffering improves the performance of file I/O operations. Reading or writing large chunks of data at once is more efficient than handling many small operations.\n",
    "\n",
    "Resource Optimization: System calls are relatively expensive in terms of processing time and resources. Buffering minimizes the number of these calls, leading to better resource utilization.\n",
    "\n",
    "Smooth Data Handling: Buffering allows for smoother and more predictable data handling, especially when dealing with large files or slow I/O devices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97971555-d540-4b8a-bfbe-90a9a9847f9a",
   "metadata": {},
   "source": [
    "# 7  Describe the steps involved in implementing buffered file handling in a programming language of your\n",
    "# choice\n",
    "\n",
    "Steps for Buffered File Handling in Python\n",
    "Open the File with Buffering: When you open a file, specify the buffering behavior. Python’s open function includes a buffering parameter that allows you to control the buffer size.\n",
    "\n",
    "Specify the Mode: Determine the mode in which you want to open the file (e.g., read, write, append). The mode also affects how buffering is handled.\n",
    "\n",
    "Perform Read/Write Operations: Conduct read or write operations. Buffered I/O will automatically manage the buffer.\n",
    "\n",
    "Close the File: Ensure the file is properly closed to flush any remaining data from the buffer to the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8073f15-f070-490d-bb32-181c00dda56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: The file at example.txt was not found.\n"
     ]
    }
   ],
   "source": [
    "# 8  Write a Python function to read a text file using buffered reading and return its contents&\n",
    "\n",
    "def read_file_buffered(file_path, buffer_size=4096):\n",
    "\n",
    "    contents = []\n",
    "    try:\n",
    "        with open(file_path, 'r', buffering=buffer_size) as file:\n",
    "            while True:\n",
    "                chunk = file.read(buffer_size)\n",
    "                if not chunk:\n",
    "                    break\n",
    "                contents.append(chunk)\n",
    "    except FileNotFoundError:\n",
    "        return f\"Error: The file at {file_path} was not found.\"\n",
    "    except IOError as e:\n",
    "        return f\"Error: An I/O error occurred: {e}\"\n",
    "\n",
    "    return ''.join(contents)\n",
    "\n",
    "\n",
    "file_path = 'example.txt'\n",
    "content = read_file_buffered(file_path)\n",
    "print(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e75976-e548-476b-baf2-5ee193ee12db",
   "metadata": {},
   "source": [
    "# 9 What are the advantages of using buffered reading over direct file reading in Pytho\n",
    "\n",
    "Buffered reading offers several advantages over direct file reading in Python. Here are some of the key benefits:\n",
    "\n",
    "1. Improved Performance\n",
    "Reduced System Calls: Buffered reading reduces the number of system calls by reading larger chunks of data at a time, rather than performing many small read operations. System calls are relatively expensive operations, and minimizing them can significantly improve performance.\n",
    "Efficient Use of I/O: By reading data in larger blocks, buffered reading makes better use of the underlying I/O system. This is particularly beneficial when reading from disk or network sources where each I/O operation can have significant overhead.\n",
    "2. Resource Management\n",
    "Memory Usage: Buffered reading allows for controlled memory usage by specifying the buffer size. This can help in managing and optimizing memory consumption, especially when dealing with large files.\n",
    "Reduced CPU Load: By minimizing the number of read operations, buffered reading can reduce CPU load, allowing for more efficient execution of other tasks.\n",
    "3. Smoother Data Handling\n",
    "Consistent Data Flow: Buffered reading can provide a more consistent flow of data, which is useful for applications that process data in chunks. This can be important for streaming applications or when processing large datasets in real-time.\n",
    "Line Buffering: For text files, line buffering can be used to read data line by line, which is convenient for many text processing tasks.\n",
    "4. Error Handling and Robustness\n",
    "Error Isolation: Buffered reading can help isolate errors related to I/O operations. By handling larger chunks of data at once, there are fewer opportunities for errors to occur compared to handling numerous small reads.\n",
    "Automatic Flushing: When using with statements for file operations, buffered reading ensures that buffers are flushed and files are properly closed even if an error occurs, improving the robustness of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcc8f609-cfc2-40ba-8410-e972bb5123f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10  Write a Python code snippet to append content to a file using buffered writing\n",
    "def append_to_file_buffered(file_path, content, buffer_size=4096):\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'a', buffering=buffer_size) as file:\n",
    "            file.write(content)\n",
    "    except IOError as e:\n",
    "        print(f\"Error: An I/O error occurred: {e}\")\n",
    "\n",
    "\n",
    "file_path = 'example.txt'\n",
    "content_to_append = \"This is the appended content.\\n\"\n",
    "append_to_file_buffered(file_path, content_to_append)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f094920c-1f07-4c87-b47d-53c967e85314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content written to example.txt\n",
      "File example.txt is closed\n"
     ]
    }
   ],
   "source": [
    "#11 Write a Python function that demonstrates the use of close() method on a file&\n",
    "\n",
    "def write_and_close_file(file_path, content):\n",
    "\n",
    "    try:\n",
    "        \n",
    "        file = open(file_path, 'w')\n",
    "        \n",
    "        file.write(content)\n",
    "        print(f\"Content written to {file_path}\")\n",
    "    except IOError as e:\n",
    "        print(f\"Error: An I/O error occurred: {e}\")\n",
    "    finally:\n",
    "       \n",
    "        file.close()\n",
    "        print(f\"File {file_path} is closed\")\n",
    "\n",
    "file_path = 'example.txt'\n",
    "content_to_write = \"This is the content to be written to the file.\\n\"\n",
    "write_and_close_file(file_path, content_to_write)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a6e9032-0dee-4212-94ea-012711e5a2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file object has been detached.\n",
      "Expected error: raw stream has been detached\n",
      "Raw stream for example.bin is closed\n"
     ]
    }
   ],
   "source": [
    "# 12 Create a Python function to showcase the detach() method on a file object&\n",
    "\n",
    "def demonstrate_detach(file_path, content):\n",
    "\n",
    "    import io\n",
    "\n",
    "    try:\n",
    "        # Open the file in binary write mode\n",
    "        file = open(file_path, 'wb')\n",
    "        \n",
    "        # Write the content to the file\n",
    "        file.write(content.encode('utf-8'))\n",
    "        file.flush()  # Ensure all data is written to the file\n",
    "\n",
    "        # Detach the underlying raw stream from the buffer\n",
    "        raw = file.detach()\n",
    "        print(\"The file object has been detached.\")\n",
    "        \n",
    "        # Demonstrate that the file object is no longer usable\n",
    "        try:\n",
    "            file.write(b\"This will fail.\")\n",
    "        except ValueError as e:\n",
    "            print(f\"Expected error: {e}\")\n",
    "        \n",
    "        # Demonstrate that the raw stream can still be used\n",
    "        raw.write(b\"This is written to the raw stream.\")\n",
    "        \n",
    "    except IOError as e:\n",
    "        print(f\"Error: An I/O error occurred: {e}\")\n",
    "    finally:\n",
    "        # Close the raw stream\n",
    "        raw.close()\n",
    "        print(f\"Raw stream for {file_path} is closed\")\n",
    "\n",
    "# Example usage\n",
    "file_path = 'example.bin'\n",
    "content_to_write = \"This is the content to be written to the file.\"\n",
    "demonstrate_detach(file_path, content_to_write)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f240644-0cce-4904-a9b7-947cd8ae5290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the first line:\n",
      "Line 1: This is the first line.\n",
      "\n",
      "Reading the second line:\n",
      "Line 2: This is the second line.\n",
      "\n",
      "Reading the third line:\n",
      "Line 3: This is the third line.\n",
      "\n",
      "Reading from the 10th character onwards:\n",
      "is is the first line.\n",
      "Line 2: This is the second line.\n",
      "Line 3: This is the third line.\n"
     ]
    }
   ],
   "source": [
    "# 13 Write a Python function to demonstrate the use of the seek() method to change the file position&\n",
    "\n",
    "def demonstrate_seek(file_path):\n",
    "\n",
    "    try:\n",
    "        # Write some initial content to the file\n",
    "        with open(file_path, 'w') as file:\n",
    "            file.write(\"Line 1: This is the first line.\\n\")\n",
    "            file.write(\"Line 2: This is the second line.\\n\")\n",
    "            file.write(\"Line 3: This is the third line.\\n\")\n",
    "\n",
    "        # Open the file for reading\n",
    "        with open(file_path, 'r') as file:\n",
    "            # Read the first line\n",
    "            print(\"Reading the first line:\")\n",
    "            print(file.readline().strip())\n",
    "\n",
    "            # Move the file pointer to the beginning of the second line\n",
    "            file.seek(0)  # Move to the start of the file\n",
    "            file.readline()  # Read the first line to move the pointer to the second line\n",
    "            print(\"\\nReading the second line:\")\n",
    "            print(file.readline().strip())\n",
    "\n",
    "            # Move the file pointer to the beginning of the third line\n",
    "            file.seek(0)  # Move to the start of the file\n",
    "            file.readline()  # Read the first line\n",
    "            file.readline()  # Read the second line to move the pointer to the third line\n",
    "            print(\"\\nReading the third line:\")\n",
    "            print(file.readline().strip())\n",
    "\n",
    "            # Move the file pointer to an arbitrary position (e.g., 10th character)\n",
    "            file.seek(10)\n",
    "            print(\"\\nReading from the 10th character onwards:\")\n",
    "            print(file.read().strip())\n",
    "\n",
    "    except IOError as e:\n",
    "        print(f\"Error: An I/O error occurred: {e}\")\n",
    "\n",
    "# Example usage\n",
    "file_path = 'example.txt'\n",
    "demonstrate_seek(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4096e943-7fb5-4cfd-a3f2-5a2b5d110e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file descriptor for example.txt is 62\n"
     ]
    }
   ],
   "source": [
    "# 14 Create a Python function to return the file descriptor (integer number) of a file using the fileno() method&\n",
    "\n",
    "def get_file_descriptor(file_path):\n",
    "\n",
    "    try:\n",
    "        # Open the file in read mode\n",
    "        with open(file_path, 'r') as file:\n",
    "            # Get the file descriptor using the fileno() method\n",
    "            file_descriptor = file.fileno()\n",
    "            return file_descriptor\n",
    "    except IOError as e:\n",
    "        print(f\"Error: An I/O error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "file_path = 'example.txt'\n",
    "file_descriptor = get_file_descriptor(file_path)\n",
    "if file_descriptor is not None:\n",
    "    print(f\"The file descriptor for {file_path} is {file_descriptor}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e17b276-bd5d-481b-8904-21301b09599c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current position of the file's cursor is 10 bytes.\n"
     ]
    }
   ],
   "source": [
    "# 15 rite a Python function to return the current position of the file's object using the tell() method&\n",
    "\n",
    "def get_file_position(file_path):\n",
    "\n",
    "    try:\n",
    "        # Open the file in read mode\n",
    "        with open(file_path, 'r') as file:\n",
    "            # Read the first few bytes to change the file's position\n",
    "            file.read(10)  # Example: read the first 10 bytes\n",
    "            # Get the current position using the tell() method\n",
    "            current_position = file.tell()\n",
    "            return current_position\n",
    "    except IOError as e:\n",
    "        print(f\"Error: An I/O error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "file_path = 'example.txt'\n",
    "position = get_file_position(file_path)\n",
    "if position is not None:\n",
    "    print(f\"The current position of the file's cursor is {position} bytes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "150198c9-70ce-4b92-a2ea-533228ed8a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log message has been written to app.log\n"
     ]
    }
   ],
   "source": [
    "# 16 reate a Python program that logs a message to a file using the logging module&\n",
    "\n",
    "import logging\n",
    "\n",
    "def setup_logger(log_file_path):\n",
    "\n",
    "    \n",
    "    logging.basicConfig(\n",
    "        filename=log_file_path,         \n",
    "        level=logging.DEBUG,            \n",
    "        format='%(asctime)s - %(levelname)s - %(message)s'  \n",
    "    )\n",
    "\n",
    "def log_message(message):\n",
    "\n",
    "    logging.info(message)\n",
    "\n",
    "\n",
    "log_file_path = 'app.log'  \n",
    "setup_logger(log_file_path)  \n",
    "log_message('This is a log message.')  \n",
    "print(f'Log message has been written to {log_file_path}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7ceb7a-b2e2-48c6-9beb-451b591023b7",
   "metadata": {},
   "source": [
    "# 17 Explain the importance of logging levels in Python's logging module&\n",
    "\n",
    "1. Message Prioritization\n",
    "Severity Levels: Logging levels allow you to prioritize messages according to their severity. This helps in focusing on more critical issues while filtering out less important ones.\n",
    "Granular Control: You can control the level of detail you want in your logs by setting an appropriate logging level. For example, setting the level to ERROR will only log error messages and ignore less severe messages like debug information.\n",
    "2. Efficient Debugging\n",
    "Debugging Information: During development or debugging, you might need detailed information about the program’s execution. By setting the logging level to DEBUG, you get verbose output that can help diagnose issues.\n",
    "Production Environment: In a production environment, detailed debug logs are typically not required. You can set the logging level to WARNING or ERROR to reduce log volume and focus on significant issues.\n",
    "3. Performance Considerations\n",
    "Reduced Overhead: By setting a higher logging level (e.g., WARNING or ERROR), you can reduce the overhead associated with logging. This minimizes the performance impact of logging on the application, especially in high-throughput environments.\n",
    "Selective Logging: Logging levels help in avoiding the performance hit of generating detailed logs that might not be needed in every context. This selective logging ensures that only relevant information is processed and stored.\n",
    "4. Log Filtering and Management\n",
    "Custom Log Handlers: Different log handlers can be set up with different logging levels. For example, you might want to log DEBUG messages to a file for detailed inspection while only logging ERROR messages to the console for immediate attention.\n",
    "Log Rotation and Retention: By managing logging levels effectively, you can control the volume of logs and implement log rotation or retention policies to avoid excessive log file sizes.\n",
    "5. Structured and Consistent Logging\n",
    "Consistency: Using logging levels helps maintain consistency in log messages across the application. This consistency is important for interpreting logs correctly and understanding the context of each message.\n",
    "Structured Output: Logging levels help in structuring log output, making it easier to analyze and search logs based on their severity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2746105-0aff-47ba-98cb-62cb7078a19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18  Create a Python program that uses the debugger to find the value of a variable inside a loop&\n",
    "\n",
    "import pdb\n",
    "\n",
    "def calculate_factorial(n):\n",
    "\n",
    "    factorial = 1\n",
    "    for i in range(1, n + 1):\n",
    "        factorial *= i\n",
    "        \n",
    "        pdb.set_trace()\n",
    "    return factorial\n",
    "\n",
    "\n",
    "number = 5\n",
    "result = calculate_factorial(number)\n",
    "print(f\"The factorial of {number} is {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bde6893-d8a5-434b-ade7-ebdddbac6d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 19 reate a Python program that demonstrates setting breakpoints and inspecting variables using the debugge\n",
    "\n",
    "import pdb\n",
    "\n",
    "def fibonacci(n):\n",
    "\n",
    "    fib_seq = [0, 1]\n",
    "    while len(fib_seq) < n:\n",
    "        \n",
    "        pdb.set_trace()\n",
    "        fib_seq.append(fib_seq[-1] + fib_seq[-2])\n",
    "    return fib_seq\n",
    "\n",
    "def main():\n",
    "    number = 7\n",
    "    print(f\"Calculating Fibonacci sequence up to {number}:\")\n",
    "    result = fibonacci(number)\n",
    "    print(f\"Fibonacci sequence: {result}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01701f5f-ed3f-4ccd-92d3-24f76f8514ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20  Create a Python program that uses the debugger to trace a recursive function&\n",
    "\n",
    "\n",
    "import pdb\n",
    "\n",
    "def factorial(n):\n",
    "    \n",
    "    pdb.set_trace()\n",
    "    if n == 0 or n == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return n * factorial(n - 1)\n",
    "\n",
    "def main():\n",
    "    number = 5\n",
    "    print(f\"Calculating factorial of {number}:\")\n",
    "    result = factorial(number)\n",
    "    print(f\"Factorial of {number} is {result}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe35542-f5ab-4e8c-8056-262e8fdffcda",
   "metadata": {},
   "source": [
    "# 21 Write a try-except block to handle a ZeroDivisionError&\n",
    "\n",
    "def divide_numbers(a, b):\n",
    "\n",
    "    try:\n",
    "        result = a / b\n",
    "    except ZeroDivisionError:\n",
    "        return \"Error: Division by zero is not allowed.\"\n",
    "    return result\n",
    "\n",
    "\n",
    "numerator = 10\n",
    "denominator = 0\n",
    "\n",
    "\n",
    "result = divide_numbers(numerator, denominator)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a04c537-fc49-41db-b451-4095e9803bfa",
   "metadata": {},
   "source": [
    "# 22 w does the else block work with try-excep\n",
    "\n",
    "How the else Block Works:\n",
    "\n",
    "try Block: Contains code that might raise an exception.\n",
    "except Block: Contains code that runs if an exception is raised in the try block.\n",
    "else Block: Contains code that runs if no exceptions are raised in the try block. It is executed after the try block completes successfully but before the finally block (if present)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9475c978-e4aa-45c0-ba3a-b344cf563509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 1: This is the first line.\n",
      "Line 2: This is the second line.\n",
      "Line 3: This is the third line.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 23 mplement a try-except-else block to open and read a file&\n",
    "\n",
    "def read_file(file_path):\n",
    "\n",
    "    try:\n",
    "        \n",
    "        with open(file_path, 'r') as file:\n",
    "            \n",
    "            content = file.read()\n",
    "    except FileNotFoundError:\n",
    "        \n",
    "        return \"Error: File not found.\"\n",
    "    except IOError:\n",
    "        \n",
    "        return \"Error: An I/O error occurred.\"\n",
    "    else:\n",
    "        \n",
    "        return content\n",
    "\n",
    "\n",
    "file_path = 'example.txt'\n",
    "\n",
    "\n",
    "file_content = read_file(file_path)\n",
    "print(file_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7c674c-fcf4-484d-ad94-30d005fff6ab",
   "metadata": {},
   "source": [
    "# 24  What is the purpose of the finally block in exception handling&\n",
    "\n",
    "Guaranteed Execution:\n",
    "\n",
    "Code in the finally block is guaranteed to run, no matter what happens in the try block or any associated except blocks. This ensures that critical cleanup or finalization code is executed even if an error occurs.\n",
    "Resource Management:\n",
    "\n",
    "It is commonly used for managing resources that need to be explicitly released or closed, such as files, network connections, or database connections. For example, if you open a file, you should close it to free up system resources. The finally block ensures the file is closed whether or not an exception occurs.\n",
    "Consistent Cleanup:\n",
    "\n",
    "Ensures that cleanup actions are consistent, avoiding scenarios where resources might be left open or unreleased if an error occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad0f71dd-0a4e-4b6f-8c43-5ccee7ea6d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to convert the value.\n",
      "Error: Value cannot be converted to an integer.\n"
     ]
    }
   ],
   "source": [
    "# 25 rite a try-except-finally block to handle a ValueError\n",
    "\n",
    "def convert_to_int(value):\n",
    "\n",
    "    try:\n",
    "        \n",
    "        number = int(value)\n",
    "    except ValueError:\n",
    "        \n",
    "        return \"Error: Value cannot be converted to an integer.\"\n",
    "    finally:\n",
    "        \n",
    "        print(\"Attempted to convert the value.\")\n",
    "\n",
    "    \n",
    "    return number\n",
    "\n",
    "\n",
    "user_input = \"123a\"  \n",
    "\n",
    "\n",
    "result = convert_to_int(user_input)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26676f9d-5ea1-4e0d-a036-b0f7910c7adf",
   "metadata": {},
   "source": [
    "# 26 ow multiple except blocks work in Python,\n",
    "\n",
    "Order of except Blocks:\n",
    "\n",
    "The except blocks are evaluated in the order they appear. Python will check each except block to see if the raised exception matches the exception type specified. Once a match is found, the corresponding block is executed, and the rest of the except blocks are skipped.\n",
    "This means you should order except blocks from the most specific to the most general. For example, handle FileNotFoundError before IOError, as FileNotFoundError is a subclass of IOError.\n",
    "Handling Multiple Exception Types:\n",
    "\n",
    "You can handle multiple exception types in a single except block by specifying a tuple of exceptions. This is useful when you want to handle different exceptions in the same way.\n",
    "General Exception Handling:\n",
    "\n",
    "A final except block without specifying an exception type will catch any exception not handled by the previous except blocks. This is often used as a catch-all for unexpected errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b60392b-8c90-4e38-8117-b923b4aea1af",
   "metadata": {},
   "source": [
    "# 27  What is a custom exception in Python,\n",
    "\n",
    "In Python, a custom exception is a user-defined exception class that inherits from the built-in Exception class or one of its subclasses. Custom exceptions allow you to create more meaningful and specific error messages that are tailored to the particular needs of your application. By defining custom exceptions, you can handle specific types of errors in a way that makes your code more readable and easier to maintain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0da01471-2695-4b8a-9a57-7262456251f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomError caught: Negative value is not allowed.\n"
     ]
    }
   ],
   "source": [
    "# 28 reate a custom exception class with a message'\n",
    "\n",
    "class CustomError(Exception):\n",
    "\n",
    "    def __init__(self, message):\n",
    "        \n",
    "        super().__init__(message)\n",
    "        self.message = message\n",
    "\n",
    "\n",
    "def perform_operation(value):\n",
    "\n",
    "    if value < 0:\n",
    "        raise CustomError(\"Negative value is not allowed.\")\n",
    "    return f\"Operation performed with value {value}.\"\n",
    "\n",
    "\n",
    "try:\n",
    "    result = perform_operation(-10)\n",
    "except CustomError as e:\n",
    "    print(f\"CustomError caught: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a35d661-1909-4f50-9933-179e880fedc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomException caught: Value cannot be negative.\n"
     ]
    }
   ],
   "source": [
    "# 29 rite a code to raise a custom exception in Python\n",
    "\n",
    "\n",
    "class MyCustomException(Exception):\n",
    "  \n",
    "    def __init__(self, message):\n",
    "        super().__init__(message)\n",
    "        self.message = message\n",
    "\n",
    "\n",
    "def process_value(value):\n",
    "\n",
    "    if value < 0:\n",
    "        \n",
    "        raise MyCustomException(\"Value cannot be negative.\")\n",
    "    return f\"Processed value: {value}\"\n",
    "\n",
    "\n",
    "try:\n",
    "    \n",
    "    result = process_value(-10)\n",
    "    print(result)\n",
    "except MyCustomException as e:\n",
    "    \n",
    "    print(f\"CustomException caught: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5aa4ad3-1dc8-4af5-a830-f46b9b631298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative value error: -5 is not allowed.\n"
     ]
    }
   ],
   "source": [
    "# 30 rite a function that raises a custom exception when a value is negative'\n",
    "\n",
    "class NegativeValueError(Exception):\n",
    "\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "        self.message = f\"Negative value error: {value} is not allowed.\"\n",
    "        super().__init__(self.message)\n",
    "\n",
    "def check_value(value):\n",
    "\n",
    "    if value < 0:\n",
    "        \n",
    "        raise NegativeValueError(value)\n",
    "    return f\"The value {value} is valid.\"\n",
    "\n",
    "\n",
    "try:\n",
    "    \n",
    "    result = check_value(-5)\n",
    "    print(result)\n",
    "except NegativeValueError as e:\n",
    "    \n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025c9457-c453-4672-bab9-d276eadee2af",
   "metadata": {},
   "source": [
    "# 31 hat is the role of try, except, else, and finally in handling exceptions\n",
    "\n",
    "try Block:\n",
    "\n",
    "Role: Contains code that may potentially raise an exception.\n",
    "Purpose: To execute a block of code where exceptions might occur, allowing you to handle errors without crashing the program.\n",
    "\n",
    "except Block:\n",
    "\n",
    "Role: Catches and handles exceptions raised by the try block.\n",
    "Purpose: To provide specific handling for different types of exceptions. You can have multiple except blocks to handle different exceptions in different ways.\n",
    "\n",
    "\n",
    "else Block:\n",
    "\n",
    "Role: Executes if no exceptions were raised in the try block.\n",
    "Purpose: To define code that should run only if the try block completes successfully without raising any exceptions.\n",
    "\n",
    "finally Block:\n",
    "\n",
    "Role: Executes no matter what, whether an exception was raised or not.\n",
    "Purpose: To ensure that certain cleanup actions are performed, such as closing files or releasing resources. This block is guaranteed to run regardless of the outcome of the try block."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9201c0ff-06bd-4beb-b4ba-a4c3b951f168",
   "metadata": {},
   "source": [
    "# 32 How can custom exceptions improve code readability and maintainability,\n",
    "\n",
    "1. Improved Readability\n",
    "a. Clearer Error Messages:\n",
    "\n",
    "Custom exceptions allow you to provide specific and meaningful error messages. Instead of generic exceptions, custom exceptions can convey detailed information about what went wrong, making the code easier to understand.\n",
    "\n",
    "b. Specific Exceptions for Specific Errors:\n",
    "\n",
    "Custom exceptions enable you to create specific types of exceptions for different error conditions. This specificity helps in understanding what went wrong without having to parse generic error messages.\n",
    "\n",
    "c. Meaningful Naming:\n",
    "\n",
    "Custom exceptions can be named to reflect the error conditions they represent. This naming makes the intent of the exception clearer to anyone reading the code.\n",
    "\n",
    "2. Enhanced Maintainability\n",
    "a. Centralized Error Handling:\n",
    "\n",
    "By using custom exceptions, you can centralize error handling in specific parts of your codebase. This makes it easier to manage and update error handling logic, as you only need to modify the custom exception handling rather than changing multiple places in the code.\n",
    "\n",
    "b. Easier Debugging:\n",
    "\n",
    "Custom exceptions help in debugging by providing precise information about what went wrong. This precision allows developers to quickly identify and fix issues, leading to more maintainable code.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbc0eba-15d7-4800-9abc-ff6274ea9a26",
   "metadata": {},
   "source": [
    "# 33 hat is multithreading\n",
    "\n",
    "Multithreading is a concurrent execution technique in programming where multiple threads run simultaneously within a single process. Each thread can be thought of as a separate path of execution, allowing tasks to be performed concurrently rather than sequentially. This can lead to more efficient use of CPU resources and improved performance, especially in tasks that can be parallelized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9d20a43-e957-433f-83a6-ba8e47525176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number: 0\n",
      "Number: 1\n",
      "Number: 2\n",
      "Number: 3\n",
      "Number: 4\n",
      "Thread has finished execution.\n"
     ]
    }
   ],
   "source": [
    "# 34 reate a thread in Python\n",
    "\n",
    "import threading\n",
    "import time\n",
    "\n",
    "\n",
    "def print_numbers():\n",
    "    for i in range(5):\n",
    "        print(f\"Number: {i}\")\n",
    "        time.sleep(1)  \n",
    "\n",
    "\n",
    "number_thread = threading.Thread(target=print_numbers)\n",
    "\n",
    "\n",
    "number_thread.start()\n",
    "\n",
    "\n",
    "number_thread.join()\n",
    "\n",
    "print(\"Thread has finished execution.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de2f0f2-b318-4936-bfe4-27ef527423f2",
   "metadata": {},
   "source": [
    "# 35 What is the Global Interpreter Lock (GIL) in Python\n",
    "\n",
    "The GIL is a mutex (short for mutual exclusion) that protects access to Python objects, preventing multiple native threads from executing Python bytecodes simultaneously. Essentially, it ensures that only one thread executes Python code at a time.\n",
    "\n",
    "The primary purpose of the GIL is to simplify memory management in CPython, particularly to avoid issues like race conditions and inconsistencies in memory management. By allowing only one thread to execute Python bytecode at a time, the GIL simplifies the implementation of CPython's memory management and garbage collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49812067-57b4-42f8-99b8-e72d926ce5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number: 0\n",
      "Letter: A\n",
      "Number: 1\n",
      "Letter: B\n",
      "Number: 2\n",
      "Number: 3Letter: C\n",
      "\n",
      "Number: 4\n",
      "Letter: D\n",
      "Letter: E\n",
      "Both threads have finished execution.\n"
     ]
    }
   ],
   "source": [
    "# 36 plement a simple multithreading example in Python\n",
    "\n",
    "import threading\n",
    "import time\n",
    "\n",
    "\n",
    "def print_numbers():\n",
    "    for i in range(5):\n",
    "        print(f\"Number: {i}\")\n",
    "        time.sleep(1)  #\n",
    "\n",
    "\n",
    "def print_letters():\n",
    "    for letter in 'ABCDE':\n",
    "        print(f\"Letter: {letter}\")\n",
    "        time.sleep(1.5)  \n",
    "\n",
    "\n",
    "number_thread = threading.Thread(target=print_numbers)\n",
    "letter_thread = threading.Thread(target=print_letters)\n",
    "\n",
    "\n",
    "number_thread.start()\n",
    "letter_thread.start()\n",
    "\n",
    "\n",
    "number_thread.join()\n",
    "letter_thread.join()\n",
    "\n",
    "print(\"Both threads have finished execution.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24219a63-7a8a-49f3-8a28-520c5eb5eca2",
   "metadata": {},
   "source": [
    "# 37 hat is the purpose of the `join()` method in threading,\n",
    "\n",
    "join() is used to synchronize threads. It blocks the calling thread (usually the main thread) until the thread on which join() was called has finished executing. This ensures that the calling thread waits for the specified thread to complete before proceeding.\n",
    "\n",
    "By calling join() on a thread, you ensure that the thread has completed its task. This is useful when you need to wait for one or more threads to finish their work before performing subsequent actions in the program."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7412b0-9a96-4f71-ae3d-972ba89f3579",
   "metadata": {},
   "source": [
    "# 38 escribe a scenario where multithreading would be beneficial in Python'\n",
    "\n",
    "Scenario: Web Scraping Multiple Websites\n",
    "Context:\n",
    "You need to scrape data from several websites to aggregate information for a data analysis project. Each website requires an HTTP request to fetch the data, which can involve waiting for responses from the servers.\n",
    "\n",
    "Problem:\n",
    "If you handle each HTTP request sequentially, the total time required to scrape all websites will be lengthy due to the waiting times for each server response. This sequential approach can be inefficient and time-consuming.\n",
    "\n",
    "Solution:\n",
    "Using multithreading, you can handle multiple HTTP requests concurrently, making better use of time and improving overall performance. Each thread can be responsible for fetching data from a different website, allowing them to operate simultaneously.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e630bd72-8fcd-4ba1-8f3b-56863cfdecd2",
   "metadata": {},
   "source": [
    "# 38 hat is multiprocessing in Python,\n",
    "\n",
    "Multiprocessing in Python refers to the concurrent execution of processes, each with its own Python interpreter and memory space. This allows for parallel execution of tasks, which can be particularly useful for CPU-bound operations where threads might be limited by the Global Interpreter Lock (GIL) in CPython.\n",
    "\n",
    "Key Concepts of Multiprocessing\n",
    "Process:\n",
    "\n",
    "A process is an independent program in execution. It has its own memory space and system resources. Unlike threads, processes do not share memory space and run completely independently.\n",
    "Parallel Execution:\n",
    "\n",
    "Multiprocessing allows for true parallel execution on multi-core processors. Each process can run on a separate CPU core, enabling concurrent execution of multiple tasks without being constrained by the GIL.\n",
    "Inter-Process Communication (IPC):\n",
    "\n",
    "Since processes do not share memory space, they need mechanisms for communication. Python’s multiprocessing module provides several IPC methods, such as pipes, queues, and shared memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab818ec-b63c-48c9-bb04-e66e1ba61cec",
   "metadata": {},
   "source": [
    "# 39 ow is multiprocessing different from multithreading in Python\n",
    "\n",
    "Multiprocessing\n",
    "Definition:\n",
    "\n",
    "Multiprocessing involves running multiple processes concurrently. Each process has its own Python interpreter and memory space.\n",
    "Isolation:\n",
    "\n",
    "Processes are isolated from each other. Each process has its own memory space and resources. This isolation helps prevent issues like data corruption due to concurrent access.\n",
    "Global Interpreter Lock (GIL):\n",
    "\n",
    "Multiprocessing bypasses the Global Interpreter Lock (GIL) because each process runs its own interpreter. This allows true parallelism and can fully utilize multiple CPU cores.\n",
    "Memory Usage:\n",
    "\n",
    "Each process consumes its own memory, which can lead to higher memory usage compared to threads. Data sharing between processes requires inter-process communication (IPC) mechanisms like queues, pipes, or shared memory.\n",
    "Communication:\n",
    "\n",
    "Processes communicate through IPC mechanisms provided by the multiprocessing module, such as Queue, Pipe, and Manager. IPC can introduce complexity and overhead.\n",
    "Use Cases:\n",
    "\n",
    "Ideal for CPU-bound tasks where the GIL would otherwise be a limiting factor. Suitable for tasks that benefit from true parallelism and can be isolated.\n",
    "Multithreading\n",
    "Definition:\n",
    "\n",
    "Multithreading involves running multiple threads within a single process. Threads share the same memory space and resources of the parent process.\n",
    "Isolation:\n",
    "\n",
    "Threads are not isolated; they share the same memory space. This can lead to issues like race conditions and data corruption if threads access shared resources without proper synchronization.\n",
    "Global Interpreter Lock (GIL):\n",
    "\n",
    "In CPython, threads are limited by the GIL, which allows only one thread to execute Python bytecode at a time. This prevents true parallel execution of CPU-bound tasks but does not affect I/O-bound tasks.\n",
    "Memory Usage:\n",
    "\n",
    "Threads share the same memory space, leading to lower memory overhead compared to processes. However, care must be taken to avoid issues with shared data.\n",
    "Communication:\n",
    "\n",
    "Threads communicate directly through shared memory, which can be more straightforward but requires synchronization mechanisms like locks, semaphores, or conditions to prevent data corruption.\n",
    "Use Cases:\n",
    "\n",
    "Ideal for I/O-bound tasks where threads spend time waiting for I/O operations (e.g., network requests, file I/O). Suitable for scenarios where tasks can benefit from concurrent execution without heavy computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "602eb71d-a80f-48ef-b865-cdf37929a582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process A started\n",
      "Process B started\n",
      "Process B completedProcess A completed\n",
      "\n",
      "Both processes have finished execution.\n"
     ]
    }
   ],
   "source": [
    "# 41 reate a process using the multiprocessing module in Python\n",
    "\n",
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "\n",
    "def worker_task(name):\n",
    "    print(f\"Process {name} started\")\n",
    "    time.sleep(2)  \n",
    "    print(f\"Process {name} completed\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    process1 = multiprocessing.Process(target=worker_task, args=(\"A\",))\n",
    "    process2 = multiprocessing.Process(target=worker_task, args=(\"B\",))\n",
    "\n",
    "    process1.start()\n",
    "    process2.start()\n",
    "\n",
    "\n",
    "    process1.join()\n",
    "    process2.join()\n",
    "\n",
    "    print(\"Both processes have finished execution.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1265d05a-efb6-49df-a821-12228ead7ce1",
   "metadata": {},
   "source": [
    "# 42 Explain the concept of Pool in the multiprocessing modul\n",
    "\n",
    "Key Concepts of Pool\n",
    "Process Pool:\n",
    "\n",
    "The Pool class creates a pool of worker processes. You can specify the number of processes in the pool, and the pool manages these processes for you.\n",
    "Task Distribution:\n",
    "\n",
    "The Pool class can distribute tasks to the worker processes in the pool. It provides methods to apply functions to data items either asynchronously or synchronously.\n",
    "Efficiency:\n",
    "\n",
    "Using a pool of workers allows you to efficiently utilize multiple CPU cores, making it suitable for CPU-bound tasks that can benefit from parallel execution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bcb0cd-5d23-48c3-a824-8b9720d7cc57",
   "metadata": {},
   "source": [
    "# 43 xplain inter-process communication in multiprocessing.\n",
    "\n",
    "Common IPC Mechanisms in Python’s multiprocessing Module\n",
    "Queues:\n",
    "\n",
    "Description: A Queue is a thread-safe FIFO (First In, First Out) data structure that allows processes to exchange data. It is useful for sending messages or data between processes.\n",
    "Usage: Processes can put items in a queue and retrieve items from it. The multiprocessing.Queue class provides methods such as put() to add items and get() to retrieve items.\n",
    "\n",
    "Pipes:\n",
    "\n",
    "Description: A Pipe is a two-way communication channel between two processes. It allows for bidirectional communication and is more low-level compared to queues.\n",
    "Usage: A pipe provides two endpoints, one for sending data and one for receiving data. The multiprocessing.Pipe function creates a pair of connection objects.\n",
    "\n",
    "Shared Memory:\n",
    "\n",
    "Description: Shared memory allows multiple processes to access the same data in memory. This is useful for scenarios where large amounts of data need to be shared efficiently.\n",
    "Usage: The multiprocessing.Value and multiprocessing.Array classes provide shared memory objects that can be accessed and modified by multiple processes.\n",
    "\n",
    "Managers:\n",
    "\n",
    "Description: Managers provide a higher-level API for managing shared state between processes. They support more complex data structures like lists, dictionaries, and arrays.\n",
    "Usage: The multiprocessing.Manager class creates a manager object that can manage shared data structures.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36410b78-4f26-4645-baad-8a83a583dd49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
